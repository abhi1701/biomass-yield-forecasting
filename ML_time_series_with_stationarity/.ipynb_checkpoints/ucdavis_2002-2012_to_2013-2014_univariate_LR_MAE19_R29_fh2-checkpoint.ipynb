{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a6d61b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  yield\n",
       "0      1  -0.01\n",
       "1      2   0.35\n",
       "2      3   0.40\n",
       "3      4   0.55\n",
       "4      5  -0.34"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('~/ctgan/ML_time_series_with_stationarity/data/ts_ucdavis_2002_to_2012_cuts_5678_stationary_hdr_idx.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ed05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "\n",
    "# samples_out = 10000 # total number of samples/records to generate/synthesize\n",
    "# no_stds = 1.05 # number of standard deviations within which synthesized values must fall\n",
    "# number_of_classes = (data['Class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "# data_len = len(data.index)\n",
    "# F = [] # a list of the feature vectors dataframes, one per class\n",
    "# for class_no in range(number_of_classes):\n",
    "#     df = pd.DataFrame(data[data['Class'] == class_no])\n",
    "#     F.append(df)\n",
    "\n",
    "    \n",
    "# def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "#     new_F = []\n",
    "#     for index, entry in enumerate(F):\n",
    "#         yield_ = entry['Yield (tons/acre)']\n",
    "#         mean_yield = yield_.mean()\n",
    "#         std_yield = yield_.std()\n",
    "#         total_rad = entry['Total Radiation (W/m^2)']\n",
    "#         mean_rad = total_rad.mean()\n",
    "#         std_rad = total_rad.std()\n",
    "#         total_rain = entry['Total Rainfall (mm)']\n",
    "#         mean_rain = total_rain.mean()\n",
    "#         std_rain = total_rain.std()\n",
    "#         avg_max_temp = entry['Avg Max Temp (C)']\n",
    "#         mean_max_temp = avg_max_temp.mean()\n",
    "#         std_max_temp = avg_max_temp.std()\n",
    "#         avg_min_temp = entry['Avg Min Temp (C)']\n",
    "#         mean_min_temp = avg_min_temp.mean()\n",
    "#         std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "#         new_yields = []\n",
    "#         new_rads = []\n",
    "#         new_rains = []\n",
    "#         new_max_temps = []\n",
    "#         new_min_temps = []\n",
    "        \n",
    "#         # calculate potcii: percentage of this class in input\n",
    "#         potcii = (len(entry)/no_records)\n",
    "#         no_records_to_generate = round(potcii * samples_out)\n",
    "        \n",
    "#         for i in range(no_records_to_generate):\n",
    "#             new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "#             new_yields.append(new_yield)\n",
    "            \n",
    "#             new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "#             new_rads.append(new_rad)\n",
    "            \n",
    "#             new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "#             new_rains.append(new_rain)\n",
    "        \n",
    "#             new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "#             new_max_temps.append(new_max_temp)\n",
    "            \n",
    "#             new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "#             new_min_temps.append(new_min_temp)\n",
    "            \n",
    "#         concat_yields = pd.concat([yield_, pd.DataFrame(new_yields)])\n",
    "#         concat_rads = pd.concat([total_rad, pd.DataFrame(new_rads)])\n",
    "#         concat_rain = pd.concat([total_rain, pd.DataFrame(new_rains)])\n",
    "#         concat_max_temps = pd.concat([avg_max_temp, pd.DataFrame(new_max_temps)])\n",
    "#         concat_min_temps = pd.concat([avg_min_temp, pd.DataFrame(new_min_temps)])\n",
    "#         new_df = pd.DataFrame()\n",
    "#         new_df['Yield (tons/acre)'] = concat_yields\n",
    "#         new_df['Total Radiation (W/m^2)'] = concat_rads\n",
    "#         new_df['Total Rainfall (mm)'] = concat_rain\n",
    "#         new_df['Avg Max Temp (C)'] = concat_max_temps\n",
    "#         new_df['Avg Min Temp (C)'] = concat_min_temps\n",
    "#         new_df['Class'] = index\n",
    "#         print(index)\n",
    "#         new_F.append(new_df)\n",
    "        \n",
    "#     return pd.concat(new_F)\n",
    "\n",
    "# new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fc1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = model.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe53469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data.to_csv('data/SITS_10k_0413_Beresford_2_Highmore_perCut_5.csv')\n",
    "# new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95ff074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  yield\n",
       "0      1   0.22\n",
       "1      2   0.62\n",
       "2      3  -0.09\n",
       "3      4  -0.04\n",
       "4      5  -0.46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get aggregate data\n",
    "targetDataLoc = '~/ctgan/ML_time_series_with_stationarity/data/ts_ucdavis_2013-2014_cuts_5678_stationary_hdr_idx.csv'\n",
    "\n",
    "targetDf = pd.read_csv(targetDataLoc) #pd.read_csv(targetDataLoc)\n",
    "aggDf = data #pd.read_csv(aggDataLoc)\n",
    "targetDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c823ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_Loc = '~/ctgan/ML_time_series_with_stationarity/data/ts_ucdavis_2002_to_2014_cuts_5678_hdr_idx_yields.csv'\n",
    "all_yearsDf = pd.read_csv(all_years_Loc)\n",
    "final_year_Loc = '~/ctgan/ML_time_series_with_stationarity/data/ts_ucdavis_8_avgs_through_2012_for_math.csv'\n",
    "final_yearDf = pd.read_csv(final_year_Loc)\n",
    "final_yearDf.head()\n",
    "target_year_Loc = '~/ctgan/ML_time_series_with_stationarity/data/ts_ucdavis_2013-2014_cuts_5678_hdr_idx_yields.csv'\n",
    "target_yearDf = pd.read_csv(target_year_Loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## imports\n",
    "# general\n",
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score  \n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVC  # support vector machines classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.neural_network import MLPClassifier # neural network for classification\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # adaboost for classification\n",
    "import xgboost as xgb\n",
    "# saving models\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "# import the API\n",
    "APILoc = 'API/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, APILoc)\n",
    "\n",
    "from API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the features that will not be used by the machine learning models\n",
    "\n",
    "xColumnsToKeep = [\"index\"]\n",
    "\n",
    "# the target to keep\n",
    "yColumnsToKeep = [\"yield\"]\n",
    "\n",
    "# get a dataframe containing the features and the targets\n",
    "xDf = aggDf[xColumnsToKeep]\n",
    "test_xDf = targetDf[xColumnsToKeep]\n",
    "\n",
    "yDf = aggDf[yColumnsToKeep]\n",
    "test_yDf = targetDf[yColumnsToKeep]\n",
    "\n",
    "# reset the index\n",
    "xDf = xDf.reset_index(drop=True)\n",
    "yDf = yDf.reset_index(drop=True)\n",
    "test_xDf = test_xDf.reset_index(drop=True)\n",
    "test_yDf = test_yDf.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "xCols = list(xDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48fcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide the warnings because training the neural network caues lots of warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make the parameter grids for sklearn's gridsearchcv\n",
    "rfParamGrid = {\n",
    "        'model__n_estimators': [5, 10, 25, 50, 100], # Number of estimators\n",
    "        'model__max_depth': [5, 10, 15, 20], # Maximum depth of the tree\n",
    "        'model__criterion': [\"mae\"]\n",
    "    }\n",
    "knnParamGrid ={\n",
    "        'model__n_neighbors':[2,5,10],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__leaf_size': [5, 10, 30, 50]    \n",
    "    }\n",
    "svrParamGrid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 1.0, 5.0, 10.0],\n",
    "        'model__gamma': [\"scale\", \"auto\"],\n",
    "        'model__degree': [2,3,4,5]\n",
    "    }\n",
    "nnParamGrid = {\n",
    "        'model__hidden_layer_sizes':[(3), (5), (10), (3,3), (5,5), (7,7)],\n",
    "        'model__solver': ['sgd', 'adam'],\n",
    "        'model__learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "        'model__learning_rate_init': [0.1, 0.01, 0.001]      \n",
    "    }\n",
    "\n",
    "linRegParamGrid = {}\n",
    "\n",
    "bayesParamGrid={\n",
    "        'model__n_iter':[100,300,500]\n",
    "    }\n",
    "\n",
    "dtParamGrid = {\n",
    "    'model__criterion': ['mae'],\n",
    "    'model__max_depth': [5,10,25,50,100]\n",
    "    #'model__max_depth': [5,10,25]\n",
    "    }\n",
    "\n",
    "xgbParamGrid = {}\n",
    "\n",
    "aModelList = [#(RandomForestRegressor(), rfParamGrid, \"rfTup.pkl\")]#,\n",
    "              #(KNeighborsRegressor(), knnParamGrid, \"knnTup.pkl\"),\n",
    "              #(SVC(), svrParamGrid, \"svrTup.pkl\")]#,\n",
    "             #(MLPRegressor(), nnParamGrid, \"nnTup.pkl\")]#,\n",
    "             (LinearRegression(), linRegParamGrid, \"linRegTup.pkl\")]#,\n",
    "             #(BayesianRidge(), bayesParamGrid, \"bayesTup.pkl\"),\n",
    "             #(DecisionTreeRegressor(), dtParamGrid, \"dtTup.pkl\")]\n",
    "             #(xgb.XGBRegressor(), xgbParamGrid, \"xgbTup.pkl\")]\n",
    "\n",
    "N = 10\n",
    "workingDir = 'working_dir'\n",
    "numFeatures = 1 # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52261c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  linRegTup\n",
      "Avg MAE:  811.283\n",
      "Avg R squared:  -0.627\n",
      "Best MAE:  741.248\n",
      "Best R squared:  -0.003\n",
      " \n",
      "test results on our test data: \n",
      "   yield\n",
      "0   0.22\n",
      "1   0.62\n",
      "2  -0.09\n",
      "3  -0.04\n",
      "4  -0.46\n",
      "5  -0.38\n",
      "6   0.21\n",
      "7   0.29\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/indexes/range.py:385\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 4 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msaveMLResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_yearsDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_yearDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_yearDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_xDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_yDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maModelList\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkingDir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumFeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintResults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ctgan/ML_time_series_with_stationarity/API/API.py:924\u001b[0m, in \u001b[0;36msaveMLResults\u001b[0;34m(all_yearsDf, final_yearDf, target_yearDf, xTest, yTest, N, xDf, yDf, modelList, workingDir, numFeatures, printResults)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m#print(\"Parameters of the best model: \", bestModel.best_params_)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;66;03m#print(\"Features selected by best model: \", bestFeatures)\u001b[39;00m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 924\u001b[0m m, r \u001b[38;5;241m=\u001b[39m \u001b[43mactualTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_yearsDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_yearDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_yearDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxTest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myTest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbestModel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-local results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE: \u001b[39m\u001b[38;5;124m\"\u001b[39m, m)\n",
      "File \u001b[0;32m~/ctgan/ML_time_series_with_stationarity/API/API.py:943\u001b[0m, in \u001b[0;36mactualTest\u001b[0;34m(all_yearsDf, final_yearDf, target_yearDf, xTest, yTest, yDf, model)\u001b[0m\n\u001b[1;32m    941\u001b[0m adj_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pred)):\n\u001b[0;32m--> 943\u001b[0m     adj_pred\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfinal_yearDf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myield\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m pred[i])\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjusted predictions: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/indexes/range.py:387\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "saveMLResults(all_yearsDf, final_yearDf, target_yearDf, test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737b3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
