{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a6d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield (tons/acre)</th>\n",
       "      <th>Total Radiation (W/m^2)</th>\n",
       "      <th>Total Rainfall (mm)</th>\n",
       "      <th>Avg Min Temp (C)</th>\n",
       "      <th>Avg Max Temp (C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.30</td>\n",
       "      <td>237920.06</td>\n",
       "      <td>1566.72</td>\n",
       "      <td>3.256239</td>\n",
       "      <td>15.273486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25</td>\n",
       "      <td>237920.06</td>\n",
       "      <td>1566.72</td>\n",
       "      <td>3.256239</td>\n",
       "      <td>15.273486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.21</td>\n",
       "      <td>237920.06</td>\n",
       "      <td>1566.72</td>\n",
       "      <td>3.256239</td>\n",
       "      <td>15.273486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.18</td>\n",
       "      <td>237920.06</td>\n",
       "      <td>1566.72</td>\n",
       "      <td>3.256239</td>\n",
       "      <td>15.273486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.17</td>\n",
       "      <td>237920.06</td>\n",
       "      <td>1566.72</td>\n",
       "      <td>3.256239</td>\n",
       "      <td>15.273486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Yield (tons/acre)  Total Radiation (W/m^2)  Total Rainfall (mm)  \\\n",
       "0               2.30                237920.06              1566.72   \n",
       "1               2.25                237920.06              1566.72   \n",
       "2               2.21                237920.06              1566.72   \n",
       "3               2.18                237920.06              1566.72   \n",
       "4               2.17                237920.06              1566.72   \n",
       "\n",
       "   Avg Min Temp (C)  Avg Max Temp (C)  \n",
       "0          3.256239         15.273486  \n",
       "1          3.256239         15.273486  \n",
       "2          3.256239         15.273486  \n",
       "3          3.256239         15.273486  \n",
       "4          3.256239         15.273486  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('~/ctgan/data/non_annualized_SD_0323.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ed05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot concatenate unaligned mixed dimensional NDFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 70\u001b[0m\n\u001b[1;32m     66\u001b[0m         new_F\u001b[38;5;241m.\u001b[39mappend(new_df)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(new_F)\n\u001b[0;32m---> 70\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43msynthesize_tabular_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_stds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [8], line 55\u001b[0m, in \u001b[0;36msynthesize_tabular_data\u001b[0;34m(F, samples_out, no_stds, no_classes, no_records)\u001b[0m\n\u001b[1;32m     52\u001b[0m     new_min_temp \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(mean_min_temp \u001b[38;5;241m-\u001b[39m std_min_temp\u001b[38;5;241m*\u001b[39mno_stds, mean_min_temp \u001b[38;5;241m+\u001b[39m std_min_temp\u001b[38;5;241m*\u001b[39mno_stds)\n\u001b[1;32m     53\u001b[0m     new_min_temps\u001b[38;5;241m.\u001b[39mappend(new_min_temp)\n\u001b[0;32m---> 55\u001b[0m concat_rads \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtotal_rad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_rads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m concat_rain \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([total_rain, pd\u001b[38;5;241m.\u001b[39mDataFrame(new_rains)])\n\u001b[1;32m     57\u001b[0m concat_max_temps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([avg_max_temp, pd\u001b[38;5;241m.\u001b[39mDataFrame(new_max_temps)])\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/pandas/core/reshape/concat.py:501\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m max_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate unaligned mixed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensional NDFrame objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot concatenate unaligned mixed dimensional NDFrame objects"
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "\n",
    "samples_out = 10000 # total number of samples/records to generate/synthesize\n",
    "no_stds = .6 # number of standard deviations within which synthesized values must fall\n",
    "number_of_classes = (data['Yield (tons/acre)'].unique()).size # number of unique classes in input data\n",
    "\n",
    "data_len = len(data.index)\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "for class_no in range(number_of_classes):\n",
    "    df = pd.DataFrame(data[data['Yield (tons/acre)'] == class_no])\n",
    "    F.append(df)\n",
    "\n",
    "    \n",
    "def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "    new_F = []\n",
    "    for index, entry in enumerate(F):\n",
    "        total_rad = entry['Total Radiation (W/m^2)']\n",
    "        mean_rad = total_rad.mean()\n",
    "        std_rad = total_rad.std()\n",
    "        total_rain = entry['Total Rainfall (mm)']\n",
    "        mean_rain = total_rain.mean()\n",
    "        std_rain = total_rain.std()\n",
    "        avg_max_temp = entry['Avg Max Temp (C)']\n",
    "        mean_max_temp = avg_max_temp.mean()\n",
    "        std_max_temp = avg_max_temp.std()\n",
    "        avg_min_temp = entry['Avg Min Temp (C)']\n",
    "        mean_min_temp = avg_min_temp.mean()\n",
    "        std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "        new_rads = []\n",
    "        new_rains = []\n",
    "        new_max_temps = []\n",
    "        new_min_temps = []\n",
    "        \n",
    "        # calculate potcii: percentage of this class in input\n",
    "        potcii = (len(entry)/no_records)\n",
    "        no_records_to_generate = round(potcii * samples_out)\n",
    "        \n",
    "        for i in range(no_records_to_generate):\n",
    "            new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "            new_rads.append(new_rad)\n",
    "            \n",
    "            new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "            new_rains.append(new_rain)\n",
    "        \n",
    "            new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "            new_max_temps.append(new_max_temp)\n",
    "            \n",
    "            new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "            new_min_temps.append(new_min_temp)\n",
    "            \n",
    "        concat_rads = pd.concat([total_rad, pd.DataFrame(new_rads)])\n",
    "        concat_rain = pd.concat([total_rain, pd.DataFrame(new_rains)])\n",
    "        concat_max_temps = pd.concat([avg_max_temp, pd.DataFrame(new_max_temps)])\n",
    "        concat_min_temps = pd.concat([avg_min_temp, pd.DataFrame(new_min_temps)])\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df['Total Radiation (W/m^2)'] = concat_rads\n",
    "        new_df['Total Rainfall (mm)'] = concat_rain\n",
    "        new_df['Avg Max Temp (C)'] = concat_max_temps\n",
    "        new_df['Avg Min Temp (C)'] = concat_min_temps\n",
    "        new_df['Yield (tons/acre)'] = index\n",
    "        print(index)\n",
    "        new_F.append(new_df)\n",
    "        \n",
    "    return pd.concat(new_F)\n",
    "\n",
    "new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = model.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe53469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data.to_csv('data/XGB_TV_10k_0315_SD2OH_perCut.csv')\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ff074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get aggregate data\n",
    "targetDataLoc = '~/ctgan/data/non_annualized_OH_0323.csv'\n",
    "\n",
    "targetDf = pd.read_csv(targetDataLoc) #pd.read_csv(targetDataLoc)\n",
    "aggDf = new_data #pd.read_csv(aggDataLoc)\n",
    "targetDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## imports\n",
    "# general\n",
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score  \n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVC  # support vector machines classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.neural_network import MLPClassifier # neural network for classification\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # adaboost for classification\n",
    "import xgboost as xgb\n",
    "# saving models\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "# import the API\n",
    "APILoc = 'API/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, APILoc)\n",
    "\n",
    "from API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the features that will not be used by the machine learning models\n",
    "\n",
    "xColumnsToKeep = [\"Total Radiation (W/m^2)\",\"Total Rainfall (mm)\", \"Avg Max Temp (C)\", \"Avg Min Temp (C)\"]\n",
    "\n",
    "# the target to keep\n",
    "yColumnsToKeep = [\"Yield (tons/acre)\"]\n",
    "\n",
    "# get a dataframe containing the features and the targets\n",
    "xDf = aggDf[xColumnsToKeep]\n",
    "test_xDf = targetDf[xColumnsToKeep]\n",
    "\n",
    "yDf = aggDf[yColumnsToKeep]\n",
    "test_yDf = targetDf[yColumnsToKeep]\n",
    "\n",
    "# reset the index\n",
    "xDf = xDf.reset_index(drop=True)\n",
    "yDf = yDf.reset_index(drop=True)\n",
    "test_xDf = test_xDf.reset_index(drop=True)\n",
    "test_yDf = test_yDf.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "xCols = list(xDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide the warnings because training the neural network caues lots of warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make the parameter grids for sklearn's gridsearchcv\n",
    "rfParamGrid = {\n",
    "        'model__n_estimators': [5, 10, 25, 50, 100], # Number of estimators\n",
    "        'model__max_depth': [5, 10, 15, 20], # Maximum depth of the tree\n",
    "        'model__criterion': [\"mae\"]\n",
    "    }\n",
    "knnParamGrid ={\n",
    "        'model__n_neighbors':[2,5,10],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__leaf_size': [5, 10, 30, 50]    \n",
    "    }\n",
    "svrParamGrid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 1.0, 5.0, 10.0],\n",
    "        'model__gamma': [\"scale\", \"auto\"],\n",
    "        'model__degree': [2,3,4,5]\n",
    "    }\n",
    "nnParamGrid = {\n",
    "        'model__hidden_layer_sizes':[(3), (5), (10), (3,3), (5,5), (7,7)],\n",
    "        'model__solver': ['sgd', 'adam'],\n",
    "        'model__learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "        'model__learning_rate_init': [0.1, 0.01, 0.001]      \n",
    "    }\n",
    "\n",
    "linRegParamGrid = {}\n",
    "\n",
    "bayesParamGrid={\n",
    "        'model__n_iter':[100,300,500]\n",
    "    }\n",
    "\n",
    "dtParamGrid = {\n",
    "    'model__criterion': ['mae'],\n",
    "    'model__max_depth': [5,10,25,50,100]\n",
    "    }\n",
    "\n",
    "xgbParamGrid = {}\n",
    "\n",
    "aModelList = [#(RandomForestRegressor(), rfParamGrid, \"rfTup.pkl\")]#,\n",
    "              #(KNeighborsRegressor(), knnParamGrid, \"knnTup.pkl\"),\n",
    "              #(SVC(), svrParamGrid, \"svrTup.pkl\")]#,\n",
    "             #(MLPClassifier(), nnParamGrid, \"nnTup.pkl\")]#,\n",
    "             #(LinearRegression(), linRegParamGrid, \"linRegTup.pkl\")]#,\n",
    "             #(BayesianRidge(), bayesParamGrid, \"bayesTup.pkl\"),\n",
    "             #(DecisionTreeRegressor(), dtParamGrid, \"dtTup.pkl\")]\n",
    "             (xgb.XGBRegressor(), xgbParamGrid, \"xgbTup.pkl\")]\n",
    "\n",
    "N = 10\n",
    "workingDir = 'working_dir'\n",
    "numFeatures = 4 # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52261c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saveMLResults(test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
