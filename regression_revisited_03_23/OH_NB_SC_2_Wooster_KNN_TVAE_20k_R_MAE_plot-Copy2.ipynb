{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('~/ctgan/data/non_annualized_SC_NB_OH_3Class_std_p6.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import TVAE\n",
    "\n",
    "model = TVAE()\n",
    "model.fit(data)\n",
    "\n",
    "# samples_out = 20000 # total number of samples/records to generate/synthesize\n",
    "# no_stds = .09 # number of standard deviations within which synthesized values must fall\n",
    "# number_of_classes = (data['Class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "# data_len = len(data.index)\n",
    "# F = [] # a list of the feature vectors dataframes, one per class\n",
    "# for class_no in range(number_of_classes):\n",
    "#     df = pd.DataFrame(data[data['Class'] == class_no])\n",
    "#     F.append(df)\n",
    "\n",
    "    \n",
    "# def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "#     new_F = []\n",
    "#     for index, entry in enumerate(F):\n",
    "#         yield_ = entry['Yield (tons/acre)']\n",
    "#         mean_yield = yield_.mean()\n",
    "#         std_yield = yield_.std()\n",
    "#         total_rad = entry['Total Radiation (W/m^2)']\n",
    "#         mean_rad = total_rad.mean()\n",
    "#         std_rad = total_rad.std()\n",
    "#         total_rain = entry['Total Rainfall (mm)']\n",
    "#         mean_rain = total_rain.mean()\n",
    "#         std_rain = total_rain.std()\n",
    "#         avg_max_temp = entry['Avg Max Temp (C)']\n",
    "#         mean_max_temp = avg_max_temp.mean()\n",
    "#         std_max_temp = avg_max_temp.std()\n",
    "#         avg_min_temp = entry['Avg Min Temp (C)']\n",
    "#         mean_min_temp = avg_min_temp.mean()\n",
    "#         std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "#         new_yields = []\n",
    "#         new_rads = []\n",
    "#         new_rains = []\n",
    "#         new_max_temps = []\n",
    "#         new_min_temps = []\n",
    "        \n",
    "#         # calculate potcii: percentage of this class in input\n",
    "#         potcii = (len(entry)/no_records)\n",
    "#         no_records_to_generate = round(potcii * samples_out)\n",
    "        \n",
    "#         for i in range(no_records_to_generate):\n",
    "#             new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "#             new_yields.append(new_yield)\n",
    "            \n",
    "#             new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "#             new_rads.append(new_rad)\n",
    "            \n",
    "#             new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "#             new_rains.append(new_rain)\n",
    "        \n",
    "#             new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "#             new_max_temps.append(new_max_temp)\n",
    "            \n",
    "#             new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "#             new_min_temps.append(new_min_temp)\n",
    "            \n",
    "#         concat_yields = pd.concat([yield_, pd.DataFrame(new_yields)])\n",
    "#         concat_rads = pd.concat([total_rad, pd.DataFrame(new_rads)])\n",
    "#         concat_rain = pd.concat([total_rain, pd.DataFrame(new_rains)])\n",
    "#         concat_max_temps = pd.concat([avg_max_temp, pd.DataFrame(new_max_temps)])\n",
    "#         concat_min_temps = pd.concat([avg_min_temp, pd.DataFrame(new_min_temps)])\n",
    "#         new_df = pd.DataFrame()\n",
    "#         new_df['Yield (tons/acre)'] = concat_yields\n",
    "#         new_df['Total Radiation (W/m^2)'] = concat_rads\n",
    "#         new_df['Total Rainfall (mm)'] = concat_rain\n",
    "#         new_df['Avg Max Temp (C)'] = concat_max_temps\n",
    "#         new_df['Avg Min Temp (C)'] = concat_min_temps\n",
    "#         new_df['Class'] = index\n",
    "#         print(index)\n",
    "#         new_F.append(new_df)\n",
    "        \n",
    "#     return pd.concat(new_F)\n",
    "\n",
    "# new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = model.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe53469",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('data/KNN_TVAE_20k_0605_OH_2_Wooster_3.csv')\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ff074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get aggregate data\n",
    "targetDataLoc = '~/ctgan/data/non_annualized_Wooster_OH_3Class_std_p6.csv'\n",
    "\n",
    "targetDf = pd.read_csv(targetDataLoc) #pd.read_csv(targetDataLoc)\n",
    "aggDf = new_data #pd.read_csv(aggDataLoc)\n",
    "targetDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## imports\n",
    "# general\n",
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score  \n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVC  # support vector machines classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.neural_network import MLPClassifier # neural network for classification\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # adaboost for classification\n",
    "import xgboost as xgb\n",
    "# saving models\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "# import the API\n",
    "APILoc = 'API/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, APILoc)\n",
    "\n",
    "from API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the features that will not be used by the machine learning models\n",
    "\n",
    "xColumnsToKeep = [\"Total Radiation (W/m^2)\",\"Total Rainfall (mm)\", \"Avg Max Temp (C)\", \"Avg Min Temp (C)\"]\n",
    "\n",
    "# the target to keep\n",
    "yColumnsToKeep = [\"Yield (tons/acre)\"]\n",
    "\n",
    "# get a dataframe containing the features and the targets\n",
    "xDf = aggDf[xColumnsToKeep]\n",
    "test_xDf = targetDf[xColumnsToKeep]\n",
    "\n",
    "yDf = aggDf[yColumnsToKeep]\n",
    "test_yDf = targetDf[yColumnsToKeep]\n",
    "\n",
    "# reset the index\n",
    "xDf = xDf.reset_index(drop=True)\n",
    "yDf = yDf.reset_index(drop=True)\n",
    "test_xDf = test_xDf.reset_index(drop=True)\n",
    "test_yDf = test_yDf.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "xCols = list(xDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide the warnings because training the neural network caues lots of warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make the parameter grids for sklearn's gridsearchcv\n",
    "rfParamGrid = {\n",
    "        'model__n_estimators': [5, 10, 25, 50, 100], # Number of estimators\n",
    "        'model__max_depth': [5, 10, 15, 20], # Maximum depth of the tree\n",
    "        'model__criterion': [\"mae\"]\n",
    "    }\n",
    "knnParamGrid ={\n",
    "        'model__n_neighbors':[2,5,10],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__leaf_size': [5, 10, 30, 50]    \n",
    "    }\n",
    "svrParamGrid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 1.0, 5.0, 10.0],\n",
    "        'model__gamma': [\"scale\", \"auto\"],\n",
    "        'model__degree': [2,3,4,5]\n",
    "    }\n",
    "nnParamGrid = {\n",
    "        'model__hidden_layer_sizes':[(3), (5), (10), (3,3), (5,5), (7,7)],\n",
    "        'model__solver': ['sgd', 'adam'],\n",
    "        'model__learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "        'model__learning_rate_init': [0.1, 0.01, 0.001]      \n",
    "    }\n",
    "\n",
    "linRegParamGrid = {}\n",
    "\n",
    "bayesParamGrid={\n",
    "        'model__n_iter':[100,300,500]\n",
    "    }\n",
    "\n",
    "dtParamGrid = {\n",
    "    'model__criterion': ['mae'],\n",
    "    'model__max_depth': [5,10,25,50,100]\n",
    "    }\n",
    "\n",
    "xgbParamGrid = {}\n",
    "\n",
    "aModelList = [#(RandomForestRegressor(), rfParamGrid, \"rfTup.pkl\")]#,\n",
    "              (KNeighborsRegressor(), knnParamGrid, \"knnTup.pkl\")]#,\n",
    "              #(SVC(), svrParamGrid, \"svrTup.pkl\")]#,\n",
    "             #(MLPClassifier(), nnParamGrid, \"nnTup.pkl\")]#,\n",
    "             #(LinearRegression(), linRegParamGrid, \"linRegTup.pkl\")]#,\n",
    "             #(BayesianRidge(), bayesParamGrid, \"bayesTup.pkl\"),\n",
    "             #(DecisionTreeRegressor(), dtParamGrid, \"dtTup.pkl\")]\n",
    "             #(xgb.XGBRegressor(), xgbParamGrid, \"xgbTup.pkl\")]\n",
    "\n",
    "N = 10\n",
    "workingDir = 'working_dir'\n",
    "numFeatures = 4 # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52261c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saveMLResults(test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
