{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a6d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual Avg Yield</th>\n",
       "      <th>Annual Avg Min Temp</th>\n",
       "      <th>Annual Avg Max Temp</th>\n",
       "      <th>Total Accumulated Rain</th>\n",
       "      <th>Total Accumulated Radiation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.615000</td>\n",
       "      <td>3.607579</td>\n",
       "      <td>16.450760</td>\n",
       "      <td>4320.03</td>\n",
       "      <td>589529.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.580000</td>\n",
       "      <td>2.977617</td>\n",
       "      <td>15.747898</td>\n",
       "      <td>5426.99</td>\n",
       "      <td>762918.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.223333</td>\n",
       "      <td>3.016332</td>\n",
       "      <td>15.804588</td>\n",
       "      <td>5420.95</td>\n",
       "      <td>1083330.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.497500</td>\n",
       "      <td>3.607579</td>\n",
       "      <td>16.450760</td>\n",
       "      <td>4320.03</td>\n",
       "      <td>589529.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.640000</td>\n",
       "      <td>2.977617</td>\n",
       "      <td>15.747898</td>\n",
       "      <td>5426.99</td>\n",
       "      <td>762918.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annual Avg Yield  Annual Avg Min Temp  Annual Avg Max Temp  \\\n",
       "0          1.615000             3.607579            16.450760   \n",
       "1          1.580000             2.977617            15.747898   \n",
       "2          1.223333             3.016332            15.804588   \n",
       "3          1.497500             3.607579            16.450760   \n",
       "4          1.640000             2.977617            15.747898   \n",
       "\n",
       "   Total Accumulated Rain  Total Accumulated Radiation  Class  \n",
       "0                 4320.03                    589529.46      1  \n",
       "1                 5426.99                    762918.99      1  \n",
       "2                 5420.95                   1083330.58      0  \n",
       "3                 4320.03                    589529.46      1  \n",
       "4                 5426.99                    762918.99      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "data = pd.read_csv('~/ctgan/data/annualized_SD_p5_std.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a3b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "samples_out = 10000 # total number of samples/records to generate/synthesize\n",
    "no_stds = .7 # number of standard deviations within which synthesized values must fall\n",
    "#F = data[[\"Total Radiation (W/m^2)\",\"Total Rainfall (mm)\", \"Avg Max Temp (C)\", \"Avg Min Temp (C)\"]] # the input feature matrix\n",
    "number_of_classes = (data['Class'].unique()).size # number of unique classes in input data\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "\n",
    "@jit(target=\"cuda\")\n",
    "def get_fv_dfs(data):\n",
    "    for class_no in range(number_of_classes):\n",
    "        df = pd.DataFrame(data[data['Class'] == class_no])\n",
    "        F.append(df)\n",
    "        \n",
    "    return F\n",
    "    \n",
    "# new_F = []\n",
    "# for index, entry in enumerate(F):\n",
    "#     total_rad = entry['Total Accumulated Radiation']\n",
    "#     mean_rad = total_rad.mean()\n",
    "#     std_rad = total_rad.std()\n",
    "#     total_rain = entry['Total Accumulated Rain']\n",
    "#     mean_rain = total_rain.mean()\n",
    "#     std_rain = total_rain.std()\n",
    "#     avg_max_temp = entry['Annual Avg Max Temp']\n",
    "#     mean_max_temp = avg_max_temp.mean()\n",
    "#     std_max_temp = avg_max_temp.std()\n",
    "#     avg_min_temp = entry['Annual Avg Min Temp']\n",
    "#     mean_min_temp = avg_min_temp.mean()\n",
    "#     std_min_temp = avg_min_temp.std()\n",
    "\n",
    "#     new_rads = []\n",
    "#     new_rains = []\n",
    "#     new_max_temps = []\n",
    "#     new_min_temps = []\n",
    "\n",
    "#     # calculate potcii: percentage of this class in input\n",
    "#     potcii = (len(entry)/no_records)\n",
    "#     no_records_to_generate = round(potcii * samples_out)\n",
    "\n",
    "#     for i in range(no_records_to_generate):\n",
    "#         new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "#         new_rads.append(new_rad)\n",
    "\n",
    "#         new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "#         new_rains.append(new_rain)\n",
    "\n",
    "#         new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "#         new_max_temps.append(new_max_temp)\n",
    "\n",
    "#         new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "#         new_min_temps.append(new_min_temp)\n",
    "\n",
    "#     concat_rads = pd.concat([total_rad, pd.DataFrame(new_rads)])\n",
    "#     concat_rain = pd.concat([total_rain, pd.DataFrame(new_rains)])\n",
    "#     concat_max_temps = pd.concat([avg_max_temp, pd.DataFrame(new_max_temps)])\n",
    "#     concat_min_temps = pd.concat([avg_min_temp, pd.DataFrame(new_min_temps)])\n",
    "#     new_df = pd.DataFrame()\n",
    "#     new_df['Total Accumulated Radiation'] = concat_rads\n",
    "#     new_df['Total Accumulated Rain'] = concat_rain\n",
    "#     new_df['Annual Avg Max Temp'] = concat_max_temps\n",
    "#     new_df['Annual Avg Min Temp'] = concat_min_temps\n",
    "#     new_df['Class'] = index\n",
    "#     print(index)\n",
    "#     new_F.append(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ed05b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unrecognized options: {'target'}. Known options are dict_keys(['_dbg_extend_lifetimes', '_dbg_optnone', '_nrt', 'boundscheck', 'debug', 'error_model', 'fastmath', 'forceinline', 'forceobj', 'inline', 'looplift', 'no_cfunc_wrapper', 'no_cpython_wrapper', 'no_rewrites', 'nogil', 'nopython', 'parallel', 'target_backend'])\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 72\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from sdv.tabular import CTGAN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model = CTGAN()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#new_data = synthesize_tabular_data(samples_out, no_stds, F, number_of_classes, len(data.index))\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#new_data = sits(data)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m fv_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mget_fv_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:487\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    485\u001b[0m             e\u001b[38;5;241m.\u001b[39mpatch_message(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip(), help_msg)))\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# ignore the FULL_TRACEBACKS config, this needs reporting!\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types_active_call \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:420\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    418\u001b[0m return_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     return_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Received request for compiler re-entry with the list of arguments\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# indicated by e.requested_args.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# First, check if any of these args are already Literal-ized\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     already_lit_pos \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mrequested_args\n\u001b[1;32m    426\u001b[0m                        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[i], types\u001b[38;5;241m.\u001b[39mLiteral)]\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:965\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ev\u001b[38;5;241m.\u001b[39mtrigger_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumba:compile\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mev_details):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m         cres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfolded\u001b[39m(args, kws):\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:125\u001b[0m, in \u001b[0;36m_FunctionCompiler.compile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, return_type):\n\u001b[0;32m--> 125\u001b[0m     status, retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:139\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mTypingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_failed_cache[key] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/dispatcher.py:148\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_core\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, return_type):\n\u001b[1;32m    147\u001b[0m     flags \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mFlags()\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetdescr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_as_flags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetoptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_flags(flags)\n\u001b[1;32m    151\u001b[0m     impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_implementation(args, {})\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/options.py:41\u001b[0m, in \u001b[0;36mTargetOptions.parse_as_flags\u001b[0;34m(cls, flags, options)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"Parse target options defined in ``options`` and set ``flags``\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03maccordingly.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03moptions : dict\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m opt\u001b[38;5;241m.\u001b[39mfinalize(flags, options)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flags\n",
      "File \u001b[0;32m~/miniconda3/envs/ctgan/lib/python3.9/site-packages/numba/core/options.py:66\u001b[0m, in \u001b[0;36mTargetOptions._apply\u001b[0;34m(self, flags, options)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unused:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Unread options?\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKnown options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmappings\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unrecognized options: {'target'}. Known options are dict_keys(['_dbg_extend_lifetimes', '_dbg_optnone', '_nrt', 'boundscheck', 'debug', 'error_model', 'fastmath', 'forceinline', 'forceobj', 'inline', 'looplift', 'no_cfunc_wrapper', 'no_cpython_wrapper', 'no_rewrites', 'nogil', 'nopython', 'parallel', 'target_backend'])\""
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import CTGAN\n",
    "\n",
    "# model = CTGAN()\n",
    "# model.fit(data)\n",
    "\n",
    "\n",
    "#def sits(new_F):\n",
    "#     samples_out = 10000 # total number of samples/records to generate/synthesize\n",
    "#     no_stds = .7 # number of standard deviations within which synthesized values must fall\n",
    "#     #F = data[[\"Total Radiation (W/m^2)\",\"Total Rainfall (mm)\", \"Avg Max Temp (C)\", \"Avg Min Temp (C)\"]] # the input feature matrix\n",
    "#     number_of_classes = (data['Class'].unique()).size # number of unique classes in input data\n",
    "#     F = [] # a list of the feature vectors dataframes, one per class\n",
    "#     for class_no in range(number_of_classes):\n",
    "#         df = pd.DataFrame(data[data['Class'] == class_no])\n",
    "#         F.append(df)\n",
    "        \n",
    "    #return synthesize_tabular_data(so = samples_out, no_stds, F, number_of_classes, len(data.index))\n",
    "#     new_F = []\n",
    "#     for index, entry in enumerate(F):\n",
    "#         total_rad = entry['Total Accumulated Radiation']\n",
    "#         mean_rad = total_rad.mean()\n",
    "#         std_rad = total_rad.std()\n",
    "#         total_rain = entry['Total Accumulated Rain']\n",
    "#         mean_rain = total_rain.mean()\n",
    "#         std_rain = total_rain.std()\n",
    "#         avg_max_temp = entry['Annual Avg Max Temp']\n",
    "#         mean_max_temp = avg_max_temp.mean()\n",
    "#         std_max_temp = avg_max_temp.std()\n",
    "#         avg_min_temp = entry['Annual Avg Min Temp']\n",
    "#         mean_min_temp = avg_min_temp.mean()\n",
    "#         std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "#         new_rads = []\n",
    "#         new_rains = []\n",
    "#         new_max_temps = []\n",
    "#         new_min_temps = []\n",
    "        \n",
    "#         # calculate potcii: percentage of this class in input\n",
    "#         potcii = (len(entry)/no_records)\n",
    "#         no_records_to_generate = round(potcii * samples_out)\n",
    "        \n",
    "#         for i in range(no_records_to_generate):\n",
    "#             new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "#             new_rads.append(new_rad)\n",
    "            \n",
    "#             new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "#             new_rains.append(new_rain)\n",
    "        \n",
    "#             new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "#             new_max_temps.append(new_max_temp)\n",
    "            \n",
    "#             new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "#             new_min_temps.append(new_min_temp)\n",
    "            \n",
    "#         concat_rads = pd.concat([total_rad, pd.DataFrame(new_rads)])\n",
    "#         concat_rain = pd.concat([total_rain, pd.DataFrame(new_rains)])\n",
    "#         concat_max_temps = pd.concat([avg_max_temp, pd.DataFrame(new_max_temps)])\n",
    "#         concat_min_temps = pd.concat([avg_min_temp, pd.DataFrame(new_min_temps)])\n",
    "#         new_df = pd.DataFrame()\n",
    "#         new_df['Total Accumulated Radiation'] = concat_rads\n",
    "#         new_df['Total Accumulated Rain'] = concat_rain\n",
    "#         new_df['Annual Avg Max Temp'] = concat_max_temps\n",
    "#         new_df['Annual Avg Min Temp'] = concat_min_temps\n",
    "#         new_df['Class'] = index\n",
    "#         print(index)\n",
    "#         new_F.append(new_df)\n",
    "        \n",
    "#     return pd.concat(new_F)\n",
    "\n",
    "#new_data = synthesize_tabular_data(samples_out, no_stds, F, number_of_classes, len(data.index))\n",
    "#new_data = sits(data)\n",
    "fv_dfs = get_fv_dfs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data = model.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe53469",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('data/SITS_synth5k_0215_SD2OH10_XGB_p7std.csv')\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ff074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get aggregate data\n",
    "targetDataLoc = '~/ctgan/data/annualized_OH_p5_std_1varPerYear_10.csv'\n",
    "#aggDataLoc = 'data/synth1_GA_only_063022.csv'\n",
    "\n",
    "aggDf = data #pd.read_csv(aggDataLoc)\n",
    "#aggDf = aggDf.drop(\"Unnamed: 0\",axis=1)\n",
    "targetDf = pd.read_csv(targetDataLoc)\n",
    "#targetDf = targetDf.drop(\"Unnamed: 0\",axis=1)'\n",
    "#aggDataLoc = 'data/synth1_GA_only_063022.csv'\n",
    "\n",
    "aggDf = new_data #pd.read_csv(aggDataLoc)\n",
    "#aggDf = aggDf.drop(\"Unnamed: 0\",axis=1)\n",
    "targetDf = pd.read_csv(targetDataLoc)\n",
    "#targetDf = targetDf.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## imports\n",
    "# general\n",
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score  \n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVC  # support vector machines classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.neural_network import MLPClassifier # neural network for classification\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # adaboost for classification\n",
    "import xgboost as xgb\n",
    "# saving models\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "# import the API\n",
    "APILoc = 'API/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, APILoc)\n",
    "\n",
    "from API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the features that will not be used by the machine learning models\n",
    "\n",
    "# the features to keep:\n",
    "# xColumnsToKeep = [\"Julian Day\", \"Time Since Sown (Days)\", \"Time Since Last Harvest (Days)\", \"Total Radiation (MJ/m^2)\",\n",
    "#                \"Total Rainfall (mm)\", \"Avg Air Temp (C)\", \"Avg Min Temp (C)\", \"Avg Max Temp (C)\",\n",
    "#                  \"Avg Soil Moisture (%)\", \"Day Length (hrs)\"], \"Percent Cover (%)\"]\n",
    "\n",
    "#xColumnsToKeep = [\"Total Radiation (W/m^2)\",\"Total Rainfall (mm)\", \"Avg Max Temp (C)\", \"Avg Min Temp (C)\"]\n",
    "xColumnsToKeep = [\"Total Accumulated Radiation\",\"Total Accumulated Rain\", \"Annual Avg Max Temp\", \"Annual Avg Min Temp\"]\n",
    "\n",
    "#xColumnsToKeep = [\"Julian Day\", \"Time Since Sown (Days)\", \"Total Radiation (MJ/m^2)\", \"Total Rainfall (mm)\"]\n",
    "\n",
    "# the target to keep\n",
    "yColumnsToKeep = [\"Class\"]\n",
    "\n",
    "# get a dataframe containing the features and the targets\n",
    "xDf = aggDf[xColumnsToKeep]\n",
    "test_xDf = targetDf[xColumnsToKeep]\n",
    "yDf = aggDf[yColumnsToKeep]\n",
    "test_yDf = targetDf[yColumnsToKeep]\n",
    "\n",
    "# reset the index\n",
    "xDf = xDf.reset_index(drop=True)\n",
    "yDf = yDf.reset_index(drop=True)\n",
    "test_xDf = test_xDf.reset_index(drop=True)\n",
    "test_yDf = test_yDf.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "xCols = list(xDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide the warnings because training the neural network caues lots of warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make the parameter grids for sklearn's gridsearchcv\n",
    "rfParamGrid = {\n",
    "        'model__n_estimators': [5, 10, 25, 50, 100], # Number of estimators\n",
    "        'model__max_depth': [5, 10, 15, 20], # Maximum depth of the tree\n",
    "        'model__criterion': [\"gini\"]\n",
    "    }\n",
    "knnParamGrid ={\n",
    "        'model__n_neighbors':[2,5,10],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__leaf_size': [5, 10, 30, 50]    \n",
    "    }\n",
    "svrParamGrid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 1.0, 5.0, 10.0],\n",
    "        'model__gamma': [\"scale\", \"auto\"],\n",
    "        'model__degree': [2,3,4,5]\n",
    "    }\n",
    "nnParamGrid = {\n",
    "        'model__hidden_layer_sizes':[(3), (5), (10), (3,3), (5,5), (7,7)],\n",
    "        'model__solver': ['sgd', 'adam'],\n",
    "        'model__learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "        'model__learning_rate_init': [0.1, 0.01, 0.001]      \n",
    "    }\n",
    "\n",
    "linRegParamGrid = {}\n",
    "\n",
    "bayesParamGrid={\n",
    "        'model__n_iter':[100,300,500]\n",
    "    }\n",
    "\n",
    "dtParamGrid = {\n",
    "    'model__criterion': ['gini'],\n",
    "    'model__max_depth': [5,10,25,50,100]\n",
    "    }\n",
    "\n",
    "xgbParamGrid = {}\n",
    "\n",
    "aModelList = [#(RandomForestClassifier(), rfParamGrid, \"rfTup.pkl\")]#,\n",
    "              #(KNeighborsRegressor(), knnParamGrid, \"knnTup.pkl\"),\n",
    "              #(SVC(), svrParamGrid, \"svrTup.pkl\")]#,\n",
    "             #(MLPClassifier(), nnParamGrid, \"nnTup.pkl\")]#,\n",
    "             #(LinearRegression(), linRegParamGrid, \"linRegTup.pkl\")]#,\n",
    "             #(BayesianRidge(), bayesParamGrid, \"bayesTup.pkl\"),\n",
    "             #(DecisionTreeClassifier(), dtParamGrid, \"dtTup.pkl\")]\n",
    "             (xgb.XGBClassifier(), xgbParamGrid, \"xgbTup.pkl\")]\n",
    "\n",
    "N = 10\n",
    "workingDir = 'working_dir'\n",
    "numFeatures = 4 # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52261c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMLResults(test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
